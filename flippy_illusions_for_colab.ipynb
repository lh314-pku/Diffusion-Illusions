{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1sgfbO7i2KK"
      },
      "source": [
        "# Flippy Illusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX4qkH_B_LWe"
      },
      "source": [
        "Hi! Welcome to the official colab demo for our demo \"Diffusion Illusions: Hiding Images in Plain Sight\". [https://ryanndagreat.github.io/Diffusion-Illusions/](https://ryanndagreat.github.io/Diffusion-Illusions/)\n",
        "\n",
        "This project was inspired by our paper \"Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors\". The Peekaboo project website: [https://ryanndagreat.github.io/peekaboo/](https://ryanndagreat.github.io/peekaboo/)\n",
        "\n",
        "Instructions:\n",
        "\n",
        "0. Go to the Runtime menu, and make sure this notebook is using GPU!\n",
        "1. Run the top 2 code cells (one cleans colab's junk and downloads the source code, while the other installs python packages)\n",
        "2. Click 'Runtime', then 'Restart Runtime'. You need to do this the first time you open this notebook to avoid weird random errors from the pip installations.\n",
        "3. Run code cells to load stable diffusion. The first time you run it it will take a few minutes to download; subsequent times won't take long at all though.\n",
        "4. Run all the cells below that, and customize prompt_a and prompt_b!\n",
        "5. Take the result top_image and bottom_image, print them out, and shine a backlight through them like shown in the Diffusion Illusion website (link above!)\n",
        "\n",
        "I may also create a YouTube tutorial if there's interest. Let me know if this would be helpful!\n",
        "\n",
        "This notebook was written by Ryan Burgert. Feel free to reach out to me at rburgert@cs.stonybrook.edu if you have any questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "80riJZ7f_LyL",
        "outputId": "2c77ce6b-8b11-4cba-f7a0-8f82972f90c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "rm: refusing to remove '.' or '..' directory: skipping '.'\n",
            "rm: refusing to remove '.' or '..' directory: skipping '..'\n",
            "Cloning into '.'...\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "if [ ! -d \".git\" ]; then\n",
        "    rm -rf * .*; #Get rid of Colab's default junk files\n",
        "    git clone -b master https://github.com/RyannDaGreat/Diffusion-Illusions .\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGDndq0_bch2",
        "outputId": "c05e6391-7d7c-4359-e42e-bc3cd34f45c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops==0.4.1 (from -r requirements.txt (line 1))\n",
            "  Downloading einops-0.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting icecream==2.1.2 (from -r requirements.txt (line 2))\n",
            "  Downloading icecream-2.1.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting imageio==2.21.3 (from -r requirements.txt (line 3))\n",
            "  Downloading imageio-2.21.3-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting matplotlib==3.5.3 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.5.3.tar.gz (35.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python==4.6.0.66 (from -r requirements.txt (line 5))\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pandas==1.4.3 (from -r requirements.txt (line 6))\n",
            "  Downloading pandas-1.4.3.tar.gz (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (13.9.4)\n",
            "Collecting rich (from -r requirements.txt (line 7))\n",
            "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting tensorboardX==2.5 (from -r requirements.txt (line 8))\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tqdm==4.64.0 (from -r requirements.txt (line 9))\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py3nvml (from -r requirements.txt (line 10))\n",
            "  Downloading py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.19.0)\n",
            "Collecting tensorboard (from -r requirements.txt (line 11))\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.16.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.57.3)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.36.0)\n",
            "Collecting rp (from -r requirements.txt (line 15))\n",
            "  Downloading rp-0.1.1372.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (1.13)\n",
            "Collecting oldest-supported-numpy (from -r requirements.txt (line 17))\n",
            "  Using cached oldest_supported_numpy-2023.12.21-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting colorama>=0.3.9 (from icecream==2.1.2->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from icecream==2.1.2->-r requirements.txt (line 2)) (2.19.2)\n",
            "Collecting executing>=0.3.1 (from icecream==2.1.2->-r requirements.txt (line 2))\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream==2.1.2->-r requirements.txt (line 2))\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imageio==2.21.3->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio==2.21.3->-r requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==1.4.3->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from tensorboardX==2.5->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.12/dist-packages (from tensorboardX==2.5->-r requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->-r requirements.txt (line 7)) (4.0.0)\n",
            "Collecting xmltodict (from py3nvml->-r requirements.txt (line 10))\n",
            "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->-r requirements.txt (line 14)) (8.7.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from diffusers->-r requirements.txt (line 14)) (0.28.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from rp->-r requirements.txt (line 15)) (0.2.14)\n",
            "Collecting stackprinter (from rp->-r requirements.txt (line 15))\n",
            "  Downloading stackprinter-0.2.12-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from rp->-r requirements.txt (line 15)) (7.5.0)\n",
            "Collecting jedi (from rp->-r requirements.txt (line 15))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from rp->-r requirements.txt (line 15)) (0.3.8)\n",
            "Requirement already satisfied: lazy_loader in /usr/local/lib/python3.12/dist-packages (from rp->-r requirements.txt (line 15)) (0.4)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from rp->-r requirements.txt (line 15)) (6.2.4)\n",
            "Collecting tree-sitter (from rp->-r requirements.txt (line 15))\n",
            "  Downloading tree_sitter-0.25.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10.0 kB)\n",
            "Collecting tree-sitter-python (from rp->-r requirements.txt (line 15))\n",
            "  Downloading tree_sitter_python-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tree-sitter-bash (from rp->-r requirements.txt (line 15))\n",
            "  Downloading tree_sitter_bash-0.25.1-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting numpy (from imageio==2.21.3->-r requirements.txt (line 3))\n",
            "  Using cached numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->-r requirements.txt (line 11)) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->-r requirements.txt (line 14)) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->-r requirements.txt (line 14)) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->-r requirements.txt (line 14)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->diffusers->-r requirements.txt (line 14)) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->diffusers->-r requirements.txt (line 14)) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 13)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->-r requirements.txt (line 13)) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 7)) (0.1.2)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->-r requirements.txt (line 14)) (3.23.0)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->rp->-r requirements.txt (line 15)) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->rp->-r requirements.txt (line 15)) (4.4.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi->rp->-r requirements.txt (line 15)) (0.8.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 13)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 13)) (2.5.0)\n",
            "Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading icecream-2.1.2-py2.py3-none-any.whl (8.3 kB)\n",
            "Downloading imageio-2.21.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m149.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached oldest_supported_numpy-2023.12.21-py3-none-any.whl (4.9 kB)\n",
            "Using cached numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n",
            "Downloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stackprinter-0.2.12-py3-none-any.whl (29 kB)\n",
            "Downloading tree_sitter-0.25.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (635 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_bash-0.25.1-cp310-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_python-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: matplotlib, pandas, rp\n",
            "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-3.5.3-cp312-cp312-linux_x86_64.whl size=11121948 sha256=d3f0f502454c3d983383b52553ca55837bab5fbc81edd9542cfbdf322c5390d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/df/38/5405dc27a6524b2233addfe4367898ad06d1aa92a513ae8bcc\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade -r requirements.txt\n",
        "%pip install rp --upgrade\n",
        "# You may need to restart the runtime after installing these\n",
        "# I'm not sure why this helps, but all sorts of weird random errors pop up in Colab if you don't"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAtxvveUbquu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import rp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import source.stable_diffusion as sd\n",
        "from easydict import EasyDict\n",
        "from source.learnable_textures import LearnableImageFourier\n",
        "from source.stable_diffusion_labels import NegativeLabel\n",
        "from itertools import chain\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7A1Fw50eDjJ"
      },
      "outputs": [],
      "source": [
        "#ONLY GOOD PROMPTS HERE\n",
        "example_prompts = rp.load_yaml_file('source/example_prompts.yaml')\n",
        "print('Available example prompts:', ', '.join(example_prompts))\n",
        "\n",
        "#These prompts are all strings - you can replace them with whatever you want! By default it lets you choose from example prompts\n",
        "#Here are some on the site! It does take some thought to come up with good ideas; the upside-down should look vaguely like the right-side up to work nicely\n",
        "# prompt_a, prompt_b = rp.gather(example_prompts, 'victorial_dress victorial_dress'.split())\n",
        "# prompt_a, prompt_b = rp.gather(example_prompts, 'pencil_giraffe_head pencil_penguin'.split())\n",
        "# prompt_a, prompt_b = rp.gather(example_prompts, 'sailing_ship sailing_ship'.split())\n",
        "\n",
        "prompt_a = \"A penguin wearing sunglasses on a white background\"\n",
        "prompt_b = \"A rooster wearing overalls\"\n",
        "\n",
        "negative_prompt = ''\n",
        "\n",
        "print()\n",
        "print('Negative prompt:',repr(negative_prompt))\n",
        "print()\n",
        "print('Chosen prompts:')\n",
        "print('    prompt_a =', repr(prompt_a)) #This will be right-side up\n",
        "print('    prompt_b =', repr(prompt_b)) #This will be upside-down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0eh7vWFfPQ6"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi9Y9Zp5ejSP"
      },
      "outputs": [],
      "source": [
        "if 's' not in dir():\n",
        "    model_name=\"CompVis/stable-diffusion-v1-4\"\n",
        "    gpu='cuda:0'\n",
        "    s=sd.StableDiffusion(gpu,model_name)\n",
        "device=s.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL_pjdcFekG6"
      },
      "outputs": [],
      "source": [
        "label_a = NegativeLabel(prompt_a,negative_prompt)\n",
        "label_b = NegativeLabel(prompt_b,negative_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LoGGFTkelJJ"
      },
      "outputs": [],
      "source": [
        "#Image Parametrization and Initialization (this section takes vram)\n",
        "\n",
        "#Select Learnable Image Size (this has big VRAM implications!):\n",
        "#Note: We use implicit neural representations for better image quality\n",
        "#They're previously used in our paper \"TRITON: Neural Neural Textures make Sim2Real Consistent\" (see tritonpaper.github.io)\n",
        "# ... and that representation is based on Fourier Feature Networks (see bmild.github.io/fourfeat)\n",
        "learnable_image_maker = lambda: LearnableImageFourier(height=256, width=256, hidden_dim=256, num_features=128).to(s.device); SIZE=256\n",
        "# learnable_image_maker = lambda: LearnableImageFourier(height=512,width=512,num_features=256,hidden_dim=256,scale=20).to(s.device);SIZE=512\n",
        "\n",
        "image=learnable_image_maker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44f6FT72ems4"
      },
      "outputs": [],
      "source": [
        "learnable_image_a=lambda: image() #Right-side up\n",
        "learnable_image_b=lambda: image().rot90(k=2,dims=[1,2]) #Upside-down\n",
        "\n",
        "optim=torch.optim.SGD(image.parameters(),lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKCQQg9teoMt"
      },
      "outputs": [],
      "source": [
        "labels=[label_a,label_b]\n",
        "learnable_images=[learnable_image_a,learnable_image_b]\n",
        "\n",
        "#The weight coefficients for each prompt. For example, if we have [0,1], then only the upside-down mode will be optimized\n",
        "weights=[1,1]\n",
        "\n",
        "weights=rp.as_numpy_array(weights)\n",
        "weights=weights/weights.sum()\n",
        "weights=weights*len(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWpLV_Toertv"
      },
      "outputs": [],
      "source": [
        "#For saving a timelapse\n",
        "ims=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6-FlVZPes09"
      },
      "outputs": [],
      "source": [
        "def get_display_image():\n",
        "    return rp.tiled_images(\n",
        "        [\n",
        "            rp.as_numpy_image(learnable_image_a()),\n",
        "            rp.as_numpy_image(learnable_image_b()),\n",
        "        ],\n",
        "        length=len(learnable_images),\n",
        "        border_thickness=0,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB-Uv4Y5et8J"
      },
      "outputs": [],
      "source": [
        "NUM_ITER=5000\n",
        "\n",
        "#Set the minimum and maximum noise timesteps for the dream loss (aka score distillation loss)\n",
        "s.max_step=MAX_STEP=990\n",
        "s.min_step=MIN_STEP=10\n",
        "\n",
        "display_eta=rp.eta(NUM_ITER, title='Status')\n",
        "\n",
        "DISPLAY_INTERVAL = 200\n",
        "\n",
        "print('Every %i iterations we display an image in the form [image_a, image_b], where'%DISPLAY_INTERVAL)\n",
        "print('    image_a = (the right-side up image)')\n",
        "print('    image_b = (image_a, but upside down)')\n",
        "print()\n",
        "print('Interrupt the kernel at any time to return the currently displayed image')\n",
        "print('You can run this cell again to resume training later on')\n",
        "print()\n",
        "print('Please expect this to take quite a while to get good images (especially on the slower Colab GPU\\'s)! The longer you wait the better they\\'ll be')\n",
        "\n",
        "try:\n",
        "    for iter_num in range(NUM_ITER):\n",
        "        display_eta(iter_num) #Print the remaining time\n",
        "\n",
        "        preds=[]\n",
        "        for label,learnable_image,weight in rp.random_batch(list(zip(labels,learnable_images,weights)), batch_size=1):\n",
        "            pred=s.train_step(\n",
        "                label.embedding,\n",
        "                learnable_image()[None],\n",
        "\n",
        "                #PRESETS (uncomment one):\n",
        "                noise_coef=.1*weight,guidance_scale=60,#10\n",
        "                # noise_coef=0,image_coef=-.01,guidance_scale=50,\n",
        "                # noise_coef=0,image_coef=-.005,guidance_scale=50,\n",
        "                # noise_coef=.1,image_coef=-.010,guidance_scale=50,\n",
        "                # noise_coef=.1,image_coef=-.005,guidance_scale=50,\n",
        "                # noise_coef=.1*weight, image_coef=-.005*weight, guidance_scale=50,\n",
        "            )\n",
        "            preds+=list(pred)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if iter_num and not iter_num%(DISPLAY_INTERVAL*50):\n",
        "                #Wipe the slate every 50 displays so they don't get cut off\n",
        "                from IPython.display import clear_output\n",
        "                clear_output()\n",
        "\n",
        "            if not iter_num%DISPLAY_INTERVAL:\n",
        "                im = get_display_image()\n",
        "                ims.append(im)\n",
        "                rp.display_image(im)\n",
        "\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "except KeyboardInterrupt:\n",
        "    print()\n",
        "    print('Interrupted early at iteration %i'%iter_num)\n",
        "    im = get_display_image()\n",
        "    ims.append(im)\n",
        "    rp.display_image(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwhrgJiie3mX"
      },
      "outputs": [],
      "source": [
        "print('Right-side up image:')\n",
        "rp.display_image(rp.as_numpy_image(learnable_image_a()))\n",
        "\n",
        "print('Upside-down image:')\n",
        "rp.display_image(rp.as_numpy_image(learnable_image_b()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YJJw4dXe4JJ"
      },
      "outputs": [],
      "source": [
        "def save_run(name):\n",
        "    folder=\"untracked/flippy_illusion_runs/%s\"%name\n",
        "    if rp.path_exists(folder):\n",
        "        folder+='_%i'%time.time()\n",
        "    rp.make_directory(folder)\n",
        "    ims_names=['ims_%04i.png'%i for i in range(len(ims))]\n",
        "    with rp.SetCurrentDirectoryTemporarily(folder):\n",
        "        rp.save_images(ims,ims_names,show_progress=True)\n",
        "    print()\n",
        "    print('Saved timelapse to folder:',repr(folder))\n",
        "\n",
        "save_run('-'.join([prompt_a,prompt_b])) #You can give it a good custom name if you want!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}